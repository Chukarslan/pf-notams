id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${llm_response.output}
    is_chat_output: true
nodes:
- name: retrieve_documents
  type: python
  source:
    type: code
    path: retrieve_documents.py
  inputs:
    question: ${inputs.question}
    index_name: test-2
    embedding: ${question_embedding.output}
    search: to_replace_with_connection_name
- name: question_embedding
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: oai-connection-1
    deployment_name: test-notams-embeddings
    input: ${inputs.question}
- name: llm_response
  type: llm
  source:
    type: code
    path: llm_response.jinja2
  inputs:
    deployment_name: test-llm-notams
    temperature: 0.2
    max_tokens: 480
    question: ${inputs.question}
    prompt_text: ${user_prompt.output}
    history: ${inputs.chat_history}
  connection: oai-connection-1
  api: chat
- name: user_prompt
  type: prompt
  source:
    type: code
    path: user_prompt.jinja2
  inputs:
    documentation: ${retrieve_documents.output}
