id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${llm_response.output}
    is_chat_output: true
nodes:
- name: question_embedding
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: oai-connection-1
    deployment_name: test-notams-embeddings
    input: ${inputs.question}
- name: retrieve_documents
  type: python
  source:
    type: code
    path: retrieve_documents.py
  inputs:
    question: ${inputs.question}
    index_name: test-2
    embedding: ${question_embedding.output}
    search: to_replace_with_connection_name
- name: user_prompt
  type: prompt
  source:
    type: code
    path: user_prompt.jinja2
  inputs:
    documentation: ${retrieve_documents.output}
- name: icao_parser
  type: llm
  source:
    type: code
    path: gsd_parset.jinja2
  inputs:
    deployment_name: df-completions-instruct
    max_tokens: 100
    temperature: 0
    input: ${inputs.question}
    top_p: 1
    presence_penalty: 0
    frequency_penalty: 0
    best_of: 1
  connection: oai-connection-1
  api: completion
- name: gsd_calculator
  type: python
  source:
    type: code
    path: determine_airports.py
  inputs:
    input_airports: ${icao_parser.output}
- name: llm_response
  type: llm
  source:
    type: code
    path: llm_response.jinja2
  inputs:
    deployment_name: test-llm-notams
    temperature: 0.2
    max_tokens: 680
    question: ${inputs.question}
    prompt_text: ${user_prompt.output}
    history: ${inputs.chat_history}
    gsd_parser: ${gsd_calculator.output}
  connection: oai-connection-1
  api: chat
  activate:
    when: ""
