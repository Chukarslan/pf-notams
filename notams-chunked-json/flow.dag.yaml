id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: test-llm-notams
    max_tokens: 312
    temperature: 0.1
  connection: oai-connection-1
  api: chat
- name: input_ner
  type: prompt
  source:
    type: code
    path: input_ner.jinja2
  inputs:
    user_input: ${inputs.question}
- name: embeddings_parser
  type: llm
  source:
    type: code
    path: embeddings_parser.jinja2
  inputs:
    deployment_name: df-completions-instruct
    max_tokens: 64
    temperature: 0.1
    prompt_template: ${input_ner.output}
  connection: oai-connection-1
  api: completion
